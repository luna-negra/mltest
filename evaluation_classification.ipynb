{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48139e9a-3f90-407d-8ae9-eb9a1911249d",
   "metadata": {},
   "source": [
    "## Evaluation of Classification Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ea76b-82d8-4fe8-886f-40669baa9de2",
   "metadata": {},
   "source": [
    "### Problem of Classification without Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f1b78a-905d-4503-9b3a-f229f8f933f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# read titanic data\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19b9121-aa19-43a5-9f77-24c000641270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7877094972067039\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# create custom estimator\n",
    "class DummyClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # create default list with row len(X.shape[0]) and column 1\n",
    "        pred = np.zeros( (X.shape[0], 1), dtype=\"int32\" )\n",
    "        for i in range(X.shape[0]):\n",
    "            pred[i] = 0 if X[\"Sex\"].iloc[i] == \"male\" else 1\n",
    "        \n",
    "        return np.array(pred)\n",
    "        \n",
    "# define feature and target\n",
    "Y_data = data[[\"Survived\"]]\n",
    "X_data = data.drop([\"Survived\"], axis=1)\n",
    "\n",
    "# split train and test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=0)\n",
    "\n",
    "model = DummyClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "pred = model.predict(X_test)\n",
    "score = accuracy_score(pred, Y_test)\n",
    "\n",
    "# accuracy: apprx 78%\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f71d0-5944-465a-a76e-f0da39a2eb62",
   "metadata": {},
   "source": [
    "- Simple Estimator can predict test set as 78%, so using accuracy_score is very dangerous.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37967fcb-ef2a-47b9-bc70-84ea6baa0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem demonstration with imbalanced dataset\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# read MNIST dataset\n",
    "# digits: <sklearn.utils._bunch.Bunch>\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "079a3504-ef13-4e12-bd72-1029b022b4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Test Set: (450, 64)\n",
      "Distribution of Test Set\n",
      "0    405\n",
      "1     45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create custom estimator\n",
    "class DummyEstimator2(BaseEstimator):\n",
    "    def fit(self, X, Y=None):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.zeros( (len(X), 1), dtype=bool)\n",
    "        \n",
    "# y: create imbalance targets\n",
    "y = (digits.target==7).astype(int)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(digits.data, y, random_state=11)\n",
    "print(f\"Size of Test Set: {X_test.shape}\")\n",
    "print(f\"Distribution of Test Set\\n{pd.Series(Y_test).value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8946adc2-1335-481e-ba6c-88b1c6a8d55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = DummyEstimator2()\n",
    "model.fit(X_train, Y_train)\n",
    "pred = model.predict(X_test)\n",
    "print(f\"Accuracy Score: {np.round(accuracy_score(pred, Y_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb2dc9e-ca93-49ab-ad7e-5afde5737a1f",
   "metadata": {},
   "source": [
    "* Only accuracy metric can not be used to evaluate the result of prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3497e1-b95c-498b-b0f2-f0b219d09724",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td>Predicted as Negative(0)</td>\n",
    "        <td>Predicted as Positive(1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Real as Negative(0)</td>\n",
    "        <td>True Negative:\n",
    "Right Prediction to Negative</td>\n",
    "        <td>False Positive:\n",
    "False Prediction to Negative</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Real as Positive(1)</td>\n",
    "        <td>False Negative:\n",
    "False Prediction to Positive</td>\n",
    "        <td>True Positive:\n",
    "True Prediction to Positive</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "* accuracy  = (TP + FN) / (TP + FP + FN + TN)\n",
    "* precision = TP / (FP + TP)\n",
    "* recall = TP / (FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d67816c7-c0a4-482f-a923-8907a2042235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Titinic data with confusion Matrix\n",
    "target_data = data[\"Survived\"]\n",
    "features_data = data.drop([\"Survived\", \"PassengerId\", \"Name\", \"Ticket\"], axis=1)\n",
    "\n",
    "#preprocessing: fill NA\n",
    "# check NA\n",
    "contain_na_features = []\n",
    "for col in features_data.columns:\n",
    "    if any(features_data[col].isnull()):\n",
    "        contain_na_features.append(col) \n",
    "\n",
    "# N/A: Age, Cabin, Embarked\n",
    "contain_na_features\n",
    "\n",
    "# fill na for Age\n",
    "features_data.fillna({\"Age\": features_data[\"Age\"].mean(), \"Embarked\": \"N\"}, inplace=True)\n",
    "\n",
    "# fill na for Cabin\n",
    "features_data[\"Cabin\"] = (features_data[\"Cabin\"].apply(lambda x: str(x)[0].upper()))\n",
    "\n",
    "# Encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Encoding \"Sex\": \"Male(1)\", \"Female(0)\"\n",
    "label = features_data[\"Sex\"].unique()\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(label)\n",
    "features_data[\"Sex\"] = encoder.transform(features_data[\"Sex\"])\n",
    "\n",
    "# Encding \"Cabin\"\n",
    "label = np.array(features_data[\"Cabin\"])\n",
    "tmp = pd.DataFrame({\"Cabin\": label})\n",
    "result = pd.get_dummies(tmp, dtype=\"int32\")\n",
    "\n",
    "for col in result.columns:\n",
    "    features_data[col] = result[col]\n",
    "\n",
    "# Encoding \"Embarked\"\n",
    "label = np.array(features_data[\"Embarked\"])\n",
    "tmp = pd.DataFrame({\"Embarked\": label})\n",
    "result = pd.get_dummies(tmp, dtype=\"int32\")\n",
    "\n",
    "for col in result.columns:\n",
    "    features_data[col] = result[col]\n",
    "\n",
    "features_data.drop([\"Cabin\", \"Embarked\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0558a759-d761-4849-aa3f-7bd13744dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix with Classification\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features_data, target_data, test_size=0.2, random_state=11)\n",
    "model.fit(X_train, Y_train)\n",
    "pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9170d872-18fa-45b1-9c04-571a18e5d836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[101  15]\n",
      " [ 17  46]]\n",
      "Accuracy_Score: 0.82\n",
      "Precision_Score: 0.75\n",
      "Recall_Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(confusion_matrix(pred, Y_test))\n",
    "print(f\"Accuracy_Score: {np.round(accuracy_score(pred, Y_test), 2)}\")\n",
    "print(f\"Precision_Score: {np.round(precision_score(pred, Y_test), 2)}\")\n",
    "print(f\"Recall_Score: {np.round(recall_score(pred, Y_test), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2246313-a865-4ab8-b12b-ff9072c08caf",
   "metadata": {},
   "source": [
    "### Precision / Recall Trade Off\n",
    "- Precision and Recall are complementary values.\n",
    "- Edit Threshold by calibrating critical value, which is called 'trade-off'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88c96a0e-48e2-4aa8-b7a5-a32b1886a80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.16666667, 0.83333333],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8       , 0.2       ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.16666667, 0.83333333],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basically, trade-off value is 50:50\n",
    "# can check the individual result by calling predict_proba from the model class which has predicted test data.\n",
    "model.predict_proba(X_test)\n",
    "\n",
    "#  Negative Probability  /  Positive Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d7222-34c1-4b35-95ed-9ba5f6fc6145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812b182-c272-41db-b1e3-9ed4a8076c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
